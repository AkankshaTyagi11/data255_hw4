{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMVoDoU0lF66oKj1Raa+4/C",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AkankshaTyagi11/hw_4/blob/main/Akanksha_Tyagi_HW_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s9Tz-NnGd8p0",
        "outputId": "63ea2259-9780-4537-babf-e0f40bedc626"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x786c443bd630>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "import torch\n",
        "import cv2\n",
        "from torchvision.models.detection import fasterrcnn_mobilenet_v3_large_fpn, FasterRCNN_MobileNet_V3_Large_FPN_Weights\n",
        "from torchvision.utils import draw_bounding_boxes\n",
        "from torchvision.io.image import read_image\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "torch.manual_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lsYDLJ4Vf9jc",
        "outputId": "b4972fb3-4dc9-4e96-88ec-4faac1fe7022"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 1"
      ],
      "metadata": {
        "id": "7LsgRkLTGc_Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1. Collect a source video. It may be necessary to divide the video into discrete image frames.\n",
        "\n",
        "Please find the collected video in the zip file. It's named as cars.mov. We directly load the video using opencv and run inference on each image frame."
      ],
      "metadata": {
        "id": "iwR3-AphGqxd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initialze a pretrained Faster RCNN model with MobilenetV3 backbone."
      ],
      "metadata": {
        "id": "29_oRbGn4i2b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "weights = FasterRCNN_MobileNet_V3_Large_FPN_Weights.COCO_V1\n",
        "mobilenet_frcnn = fasterrcnn_mobilenet_v3_large_fpn(weights=weights, box_score_thresh=0.5)\n",
        "mobilenet_frcnn.eval()\n",
        "preprocess = weights.transforms()"
      ],
      "metadata": {
        "id": "Ls8eWO4nfFnA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2. Conduct inference on each frame of the video, drawing bounding boxes around detected vehicles.\n"
      ],
      "metadata": {
        "id": "894GvGD14pOd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Open the video.\n",
        "cam = cv2.VideoCapture(\"/content/drive/MyDrive/cars.mov\")\n",
        "\n",
        "current_frame = 0\n",
        "\n",
        "# Run inference on each frame.\n",
        "images_with_boxes = []\n",
        "while(True):\n",
        "\n",
        "    # reading from frame\n",
        "    ret, frame = cam.read()\n",
        "\n",
        "    if ret:\n",
        "      # Convert to RGB\n",
        "      frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "      # Create model input\n",
        "      img = torch.from_numpy(frame).permute(2, 0, 1)\n",
        "      batch = [preprocess(img)]\n",
        "\n",
        "      with torch.no_grad()\n",
        "        # Run inference.\n",
        "        prediction = mobilenet_frcnn(batch)[0]\n",
        "\n",
        "      # Draw boxes on the frame\n",
        "      labels = [weights.meta[\"categories\"][i] for i in prediction[\"labels\"]]\n",
        "      img_box = draw_bounding_boxes(img, boxes=prediction[\"boxes\"],\n",
        "                              labels=labels,\n",
        "                              colors=\"red\",\n",
        "                              width=1)\n",
        "\n",
        "      # Save the frame with boxes in a list\n",
        "      img_box_np = img_box.permute(1, 2, 0).cpu().numpy()\n",
        "      images_with_boxes.append(img_box_np)\n",
        "\n",
        "      current_frame += 1\n",
        "      print(f'Running inference on frame no. {current_frame}')\n",
        "    else:\n",
        "        break\n",
        "\n",
        "# Release all space and windows once done\n",
        "cam.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I84BVe18flAU",
        "outputId": "68a014bb-23a2-4a5e-81f8-f4fafa777d16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running inference on frame no. 1\n",
            "Running inference on frame no. 2\n",
            "Running inference on frame no. 3\n",
            "Running inference on frame no. 4\n",
            "Running inference on frame no. 5\n",
            "Running inference on frame no. 6\n",
            "Running inference on frame no. 7\n",
            "Running inference on frame no. 8\n",
            "Running inference on frame no. 9\n",
            "Running inference on frame no. 10\n",
            "Running inference on frame no. 11\n",
            "Running inference on frame no. 12\n",
            "Running inference on frame no. 13\n",
            "Running inference on frame no. 14\n",
            "Running inference on frame no. 15\n",
            "Running inference on frame no. 16\n",
            "Running inference on frame no. 17\n",
            "Running inference on frame no. 18\n",
            "Running inference on frame no. 19\n",
            "Running inference on frame no. 20\n",
            "Running inference on frame no. 21\n",
            "Running inference on frame no. 22\n",
            "Running inference on frame no. 23\n",
            "Running inference on frame no. 24\n",
            "Running inference on frame no. 25\n",
            "Running inference on frame no. 26\n",
            "Running inference on frame no. 27\n",
            "Running inference on frame no. 28\n",
            "Running inference on frame no. 29\n",
            "Running inference on frame no. 30\n",
            "Running inference on frame no. 31\n",
            "Running inference on frame no. 32\n",
            "Running inference on frame no. 33\n",
            "Running inference on frame no. 34\n",
            "Running inference on frame no. 35\n",
            "Running inference on frame no. 36\n",
            "Running inference on frame no. 37\n",
            "Running inference on frame no. 38\n",
            "Running inference on frame no. 39\n",
            "Running inference on frame no. 40\n",
            "Running inference on frame no. 41\n",
            "Running inference on frame no. 42\n",
            "Running inference on frame no. 43\n",
            "Running inference on frame no. 44\n",
            "Running inference on frame no. 45\n",
            "Running inference on frame no. 46\n",
            "Running inference on frame no. 47\n",
            "Running inference on frame no. 48\n",
            "Running inference on frame no. 49\n",
            "Running inference on frame no. 50\n",
            "Running inference on frame no. 51\n",
            "Running inference on frame no. 52\n",
            "Running inference on frame no. 53\n",
            "Running inference on frame no. 54\n",
            "Running inference on frame no. 55\n",
            "Running inference on frame no. 56\n",
            "Running inference on frame no. 57\n",
            "Running inference on frame no. 58\n",
            "Running inference on frame no. 59\n",
            "Running inference on frame no. 60\n",
            "Running inference on frame no. 61\n",
            "Running inference on frame no. 62\n",
            "Running inference on frame no. 63\n",
            "Running inference on frame no. 64\n",
            "Running inference on frame no. 65\n",
            "Running inference on frame no. 66\n",
            "Running inference on frame no. 67\n",
            "Running inference on frame no. 68\n",
            "Running inference on frame no. 69\n",
            "Running inference on frame no. 70\n",
            "Running inference on frame no. 71\n",
            "Running inference on frame no. 72\n",
            "Running inference on frame no. 73\n",
            "Running inference on frame no. 74\n",
            "Running inference on frame no. 75\n",
            "Running inference on frame no. 76\n",
            "Running inference on frame no. 77\n",
            "Running inference on frame no. 78\n",
            "Running inference on frame no. 79\n",
            "Running inference on frame no. 80\n",
            "Running inference on frame no. 81\n",
            "Running inference on frame no. 82\n",
            "Running inference on frame no. 83\n",
            "Running inference on frame no. 84\n",
            "Running inference on frame no. 85\n",
            "Running inference on frame no. 86\n",
            "Running inference on frame no. 87\n",
            "Running inference on frame no. 88\n",
            "Running inference on frame no. 89\n",
            "Running inference on frame no. 90\n",
            "Running inference on frame no. 91\n",
            "Running inference on frame no. 92\n",
            "Running inference on frame no. 93\n",
            "Running inference on frame no. 94\n",
            "Running inference on frame no. 95\n",
            "Running inference on frame no. 96\n",
            "Running inference on frame no. 97\n",
            "Running inference on frame no. 98\n",
            "Running inference on frame no. 99\n",
            "Running inference on frame no. 100\n",
            "Running inference on frame no. 101\n",
            "Running inference on frame no. 102\n",
            "Running inference on frame no. 103\n",
            "Running inference on frame no. 104\n",
            "Running inference on frame no. 105\n",
            "Running inference on frame no. 106\n",
            "Running inference on frame no. 107\n",
            "Running inference on frame no. 108\n",
            "Running inference on frame no. 109\n",
            "Running inference on frame no. 110\n",
            "Running inference on frame no. 111\n",
            "Running inference on frame no. 112\n",
            "Running inference on frame no. 113\n",
            "Running inference on frame no. 114\n",
            "Running inference on frame no. 115\n",
            "Running inference on frame no. 116\n",
            "Running inference on frame no. 117\n",
            "Running inference on frame no. 118\n",
            "Running inference on frame no. 119\n",
            "Running inference on frame no. 120\n",
            "Running inference on frame no. 121\n",
            "Running inference on frame no. 122\n",
            "Running inference on frame no. 123\n",
            "Running inference on frame no. 124\n",
            "Running inference on frame no. 125\n",
            "Running inference on frame no. 126\n",
            "Running inference on frame no. 127\n",
            "Running inference on frame no. 128\n",
            "Running inference on frame no. 129\n",
            "Running inference on frame no. 130\n",
            "Running inference on frame no. 131\n",
            "Running inference on frame no. 132\n",
            "Running inference on frame no. 133\n",
            "Running inference on frame no. 134\n",
            "Running inference on frame no. 135\n",
            "Running inference on frame no. 136\n",
            "Running inference on frame no. 137\n",
            "Running inference on frame no. 138\n",
            "Running inference on frame no. 139\n",
            "Running inference on frame no. 140\n",
            "Running inference on frame no. 141\n",
            "Running inference on frame no. 142\n",
            "Running inference on frame no. 143\n",
            "Running inference on frame no. 144\n",
            "Running inference on frame no. 145\n",
            "Running inference on frame no. 146\n",
            "Running inference on frame no. 147\n",
            "Running inference on frame no. 148\n",
            "Running inference on frame no. 149\n",
            "Running inference on frame no. 150\n",
            "Running inference on frame no. 151\n",
            "Running inference on frame no. 152\n",
            "Running inference on frame no. 153\n",
            "Running inference on frame no. 154\n",
            "Running inference on frame no. 155\n",
            "Running inference on frame no. 156\n",
            "Running inference on frame no. 157\n",
            "Running inference on frame no. 158\n",
            "Running inference on frame no. 159\n",
            "Running inference on frame no. 160\n",
            "Running inference on frame no. 161\n",
            "Running inference on frame no. 162\n",
            "Running inference on frame no. 163\n",
            "Running inference on frame no. 164\n",
            "Running inference on frame no. 165\n",
            "Running inference on frame no. 166\n",
            "Running inference on frame no. 167\n",
            "Running inference on frame no. 168\n",
            "Running inference on frame no. 169\n",
            "Running inference on frame no. 170\n",
            "Running inference on frame no. 171\n",
            "Running inference on frame no. 172\n",
            "Running inference on frame no. 173\n",
            "Running inference on frame no. 174\n",
            "Running inference on frame no. 175\n",
            "Running inference on frame no. 176\n",
            "Running inference on frame no. 177\n",
            "Running inference on frame no. 178\n",
            "Running inference on frame no. 179\n",
            "Running inference on frame no. 180\n",
            "Running inference on frame no. 181\n",
            "Running inference on frame no. 182\n",
            "Running inference on frame no. 183\n",
            "Running inference on frame no. 184\n",
            "Running inference on frame no. 185\n",
            "Running inference on frame no. 186\n",
            "Running inference on frame no. 187\n",
            "Running inference on frame no. 188\n",
            "Running inference on frame no. 189\n",
            "Running inference on frame no. 190\n",
            "Running inference on frame no. 191\n",
            "Running inference on frame no. 192\n",
            "Running inference on frame no. 193\n",
            "Running inference on frame no. 194\n",
            "Running inference on frame no. 195\n",
            "Running inference on frame no. 196\n",
            "Running inference on frame no. 197\n",
            "Running inference on frame no. 198\n",
            "Running inference on frame no. 199\n",
            "Running inference on frame no. 200\n",
            "Running inference on frame no. 201\n",
            "Running inference on frame no. 202\n",
            "Running inference on frame no. 203\n",
            "Running inference on frame no. 204\n",
            "Running inference on frame no. 205\n",
            "Running inference on frame no. 206\n",
            "Running inference on frame no. 207\n",
            "Running inference on frame no. 208\n",
            "Running inference on frame no. 209\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "  ## Step 3. Format the results back into a video."
      ],
      "metadata": {
        "id": "PKyTmtPqHbO_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the video\n",
        "H, W = images_with_boxes[0].shape[:2]\n",
        "\n",
        "out = cv2.VideoWriter('/content/drive/MyDrive/cars_boxes.mp4', cv2.VideoWriter_fourcc(*'MP4V'), 30, (W, H))\n",
        "\n",
        "for i in range(len(images_with_boxes)):\n",
        "  img = cv2.cvtColor(images_with_boxes[i], cv2.COLOR_RGB2BGR)\n",
        "  out.write(img)\n",
        "out.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "4eIUPdrIg3DQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}